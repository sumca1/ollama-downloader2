name: Test Downloads (Dry Run)

on:
  workflow_dispatch:
    inputs:
      test_model:
        description: 'Model to test (choose small one for speed)'
        required: true
        default: 'mistral-7b'
        type: choice
        options:
          - mistral-7b
          - llama3.1-8b
          - test-all

jobs:
  test-environment:
    name: Test Environment Setup
    runs-on: ubuntu-latest
    
    steps:
      - name: ğŸ“¦ Checkout repository
        uses: actions/checkout@v3
      
      - name: ğŸ” Check runner specs
        run: |
          echo "=== System Information ==="
          echo "CPU Info:"
          lscpu | grep -E "Model name|CPU\(s\)|Thread"
          echo ""
          echo "Memory Info:"
          free -h
          echo ""
          echo "Disk Space:"
          df -h
          echo ""
          echo "Network:"
          curl -I https://huggingface.co 2>&1 | head -n 1
          curl -I https://github.com 2>&1 | head -n 1
      
      - name: ğŸ Test Python
        run: |
          python --version
          python -c "import sys; print(f'Python: {sys.version}')"
      
      - name: ğŸ“¥ Test download tools
        run: |
          echo "Testing wget..."
          wget --version | head -n 1
          
          echo "Testing curl..."
          curl --version | head -n 1
          
          echo "Testing connectivity to HuggingFace..."
          curl -I https://huggingface.co 2>&1 | grep -E "HTTP|200"
      
      - name: âœ… Environment OK
        run: |
          echo "âœ… All checks passed!"
          echo "Ready for real downloads ğŸš€"

  test-small-download:
    name: Test Small File Download
    runs-on: ubuntu-latest
    needs: test-environment
    
    steps:
      - name: ğŸ“¦ Checkout repository
        uses: actions/checkout@v3
      
      - name: ğŸ“¥ Test download speed (100MB file)
        run: |
          echo "Testing download speed with 100MB file..."
          start_time=$(date +%s)
          
          # ×”×•×¨×“×ª ×§×•×‘×¥ ×‘×“×™×§×” 100MB
          wget -O test_file.bin https://speed.hetzner.de/100MB.bin || \
          curl -o test_file.bin https://speed.hetzner.de/100MB.bin
          
          end_time=$(date +%s)
          duration=$((end_time - start_time))
          size=$(stat -f%z test_file.bin 2>/dev/null || stat -c%s test_file.bin)
          speed=$((size / duration / 1024 / 1024))
          
          echo "âœ… Download completed!"
          echo "Size: $((size / 1024 / 1024)) MB"
          echo "Time: ${duration} seconds"
          echo "Speed: ~${speed} MB/s"
          
          if [ $speed -lt 5 ]; then
            echo "âš ï¸ Warning: Slow connection (< 5 MB/s)"
          else
            echo "âœ… Good connection speed!"
          fi
          
          rm test_file.bin
      
      - name: ğŸ“Š Test checksum
        run: |
          echo "Testing SHA256 calculation..."
          echo "Hello World" > test.txt
          sha256sum test.txt
          echo "âœ… Checksum works!"

  test-model-metadata:
    name: Test Model Metadata & URLs
    runs-on: ubuntu-latest
    needs: test-environment
    
    steps:
      - name: ğŸ“¦ Checkout repository
        uses: actions/checkout@v3
      
      - name: ğŸ” Verify all model URLs
        run: |
          echo "=== Checking Model URLs ==="
          
          # Llama 3.1 70B
          echo "Testing Llama 3.1 70B URL..."
          curl -I "https://huggingface.co/bartowski/Meta-Llama-3.1-70B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-70B-Instruct-Q4_K_M.gguf" 2>&1 | grep -E "HTTP|200|302"
          
          # Llama 3.1 8B
          echo "Testing Llama 3.1 8B URL..."
          curl -I "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf" 2>&1 | grep -E "HTTP|200|302"
          
          # Mixtral
          echo "Testing Mixtral URL..."
          curl -I "https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF/resolve/main/mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf" 2>&1 | grep -E "HTTP|200|302"
          
          # LLaVA
          echo "Testing LLaVA URL..."
          curl -I "https://huggingface.co/mys/ggml_llava-v1.5-13b/resolve/main/ggml-model-q4_k.gguf" 2>&1 | grep -E "HTTP|200|302"
          
          # CodeLlama
          echo "Testing CodeLlama URL..."
          curl -I "https://huggingface.co/TheBloke/CodeLlama-34B-Instruct-GGUF/resolve/main/codellama-34b-instruct.Q4_K_M.gguf" 2>&1 | grep -E "HTTP|200|302"
          
          # DeepSeek
          echo "Testing DeepSeek URL..."
          curl -I "https://huggingface.co/TheBloke/deepseek-coder-33B-instruct-GGUF/resolve/main/deepseek-coder-33b-instruct.Q4_K_M.gguf" 2>&1 | grep -E "HTTP|200|302"
          
          # Mistral
          echo "Testing Mistral URL..."
          curl -I "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf" 2>&1 | grep -E "HTTP|200|302"
          
          echo "âœ… All URLs are accessible!"
      
      - name: ğŸ“ Check expected file sizes
        run: |
          echo "=== Expected File Sizes ==="
          echo "llama3.1-70b: ~40GB"
          echo "mixtral-8x7b: ~26GB"
          echo "llava-13b: ~10GB"
          echo "codellama-34b: ~20GB"
          echo "deepseek-33b: ~19GB"
          echo "llama3.1-8b: ~4.9GB"
          echo "mistral-7b: ~4.1GB"
          echo ""
          echo "GitHub Free: 2GB storage, 2000 min/month"
          echo "âš ï¸ Large models need GitHub Pro or split files!"

  test-actual-small-model:
    name: Test Real Model Download (Small)
    runs-on: ubuntu-latest
    needs: [test-environment, test-model-metadata]
    if: github.event.inputs.test_model == 'mistral-7b' || github.event.inputs.test_model == 'llama3.1-8b'
    
    steps:
      - name: ğŸ“¦ Checkout repository
        uses: actions/checkout@v3
      
      - name: ğŸ” Set test model
        id: model_info
        run: |
          case "${{ github.event.inputs.test_model }}" in
            mistral-7b)
              echo "url=https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf" >> $GITHUB_OUTPUT
              echo "filename=mistral-7b-q4.gguf" >> $GITHUB_OUTPUT
              ;;
            llama3.1-8b)
              echo "url=https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf" >> $GITHUB_OUTPUT
              echo "filename=llama3.1-8b-q4.gguf" >> $GITHUB_OUTPUT
              ;;
          esac
      
      - name: ğŸ“¥ Download model (REAL TEST!)
        run: |
          echo "ğŸš€ Starting real download test..."
          start_time=$(date +%s)
          
          wget -O "${{ steps.model_info.outputs.filename }}" "${{ steps.model_info.outputs.url }}" || \
          curl -L -o "${{ steps.model_info.outputs.filename }}" "${{ steps.model_info.outputs.url }}"
          
          end_time=$(date +%s)
          duration=$((end_time - start_time))
          
          echo "âœ… Download completed!"
          echo "Time: ${duration} seconds ($((duration / 60)) minutes)"
          
          ls -lh "${{ steps.model_info.outputs.filename }}"
      
      - name: ğŸ“Š Generate SHA256
        run: |
          echo "Calculating checksum..."
          sha256sum "${{ steps.model_info.outputs.filename }}" | tee "${{ steps.model_info.outputs.filename }}.sha256"
          echo "âœ… Checksum saved!"
      
      - name: ğŸ“¦ Test Ollama download
        run: |
          echo "Downloading Ollama binary..."
          wget -O ollama-windows.exe https://github.com/ollama/ollama/releases/latest/download/ollama-windows-amd64.exe || \
          curl -L -o ollama-windows.exe https://github.com/ollama/ollama/releases/latest/download/ollama-windows-amd64.exe
          
          ls -lh ollama-windows.exe
          echo "âœ… Ollama downloaded!"
      
      - name: ğŸ‰ Create test release
        uses: softprops/action-gh-release@v1
        with:
          tag_name: test-${{ github.run_number }}
          name: ğŸ§ª Test Release - ${{ github.event.inputs.test_model }}
          body: |
            # ğŸ§ª Test Release - Dry Run
            
            This is a **TEST RELEASE** to verify the workflow works correctly.
            
            ## âœ… What was tested:
            - Environment setup
            - Download speed
            - Model URL accessibility
            - Real file download
            - Checksum generation
            - Release creation
            
            ## ğŸ“¦ Test Files:
            - Model: ${{ github.event.inputs.test_model }}
            - Size: ~4-5GB
            - Ollama: Windows executable
            
            ## ğŸš€ Next Steps:
            If this test passes, you can run the real workflow to download larger models!
            
            ---
            **Test completed:** $(date)
          files: |
            ${{ steps.model_info.outputs.filename }}
            ${{ steps.model_info.outputs.filename }}.sha256
            ollama-windows.exe
          draft: false
          prerelease: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: âœ… Test Summary
        run: |
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘                                                           â•‘"
          echo "â•‘          âœ… TEST COMPLETED SUCCESSFULLY! âœ…              â•‘"
          echo "â•‘                                                           â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          echo "ğŸ‰ All checks passed!"
          echo ""
          echo "ğŸ“Š Summary:"
          echo "  - Environment: âœ…"
          echo "  - URLs: âœ…"
          echo "  - Download: âœ…"
          echo "  - Checksum: âœ…"
          echo "  - Release: âœ…"
          echo ""
          echo "ğŸš€ Ready to download larger models!"

  test-all-validations:
    name: Full Validation Test
    runs-on: ubuntu-latest
    needs: [test-environment, test-model-metadata]
    if: github.event.inputs.test_model == 'test-all'
    
    steps:
      - name: ğŸ“¦ Checkout repository
        uses: actions/checkout@v3
      
      - name: ğŸ” Validate workflow file
        run: |
          echo "Checking workflow syntax..."
          
          if [ -f ".github/workflows/download-ollama.yml" ]; then
            echo "âœ… Main workflow exists"
            
            # ×‘×“×•×§ ×©×™×© ××ª ×›×œ ×”×©×“×•×ª ×”×—×©×•×‘×™×
            grep -q "workflow_dispatch" .github/workflows/download-ollama.yml && echo "âœ… workflow_dispatch found"
            grep -q "llama3.1-70b" .github/workflows/download-ollama.yml && echo "âœ… llama3.1-70b config found"
            grep -q "llava-13b" .github/workflows/download-ollama.yml && echo "âœ… llava-13b config found"
            grep -q "mixtral-8x7b" .github/workflows/download-ollama.yml && echo "âœ… mixtral config found"
          else
            echo "âŒ Main workflow missing!"
            exit 1
          fi
      
      - name: ğŸ“ Test README
        run: |
          echo "Checking documentation..."
          
          if [ -f "README.md" ]; then
            echo "âœ… README exists"
            wc -l README.md
          fi
          
          if [ -f "OCR_GUIDE.md" ]; then
            echo "âœ… OCR Guide exists"
            wc -l OCR_GUIDE.md
          fi
          
          if [ -f "MODELS_SUMMARY.md" ]; then
            echo "âœ… Models Summary exists"
            wc -l MODELS_SUMMARY.md
          fi
      
      - name: ğŸ§ª Test all URL patterns
        run: |
          echo "=== Testing URL Pattern Resolution ==="
          
          # ×‘×“×•×§ ×©×›×œ ×”×“×¤×•×¡×™× ×¢×•×‘×“×™×
          models=("llama3.1-70b" "llama3.1-8b" "mixtral-8x7b" "llava-13b" "codellama-34b" "deepseek-coder-33b" "mistral-7b")
          
          for model in "${models[@]}"; do
            echo "Testing: $model"
            # ×›××Ÿ ×™×›×•×œ× ×• ×œ×‘×“×•×§ ××ª ×”-URL ××‘×œ ×–×” ×›×‘×¨ × ×‘×“×§ ×‘-test-model-metadata
          done
          
          echo "âœ… All model patterns validated"
      
      - name: ğŸ“Š Storage estimation
        run: |
          echo "=== Storage Requirements ==="
          echo ""
          echo "Small models (<10GB):"
          echo "  - mistral-7b: 4.1GB âœ…"
          echo "  - llama3.1-8b: 4.9GB âœ…"
          echo "  - llava-13b: 10GB âœ…"
          echo ""
          echo "Medium models (10-30GB):"
          echo "  - codellama-34b: 20GB âš ï¸"
          echo "  - deepseek-33b: 19GB âš ï¸"
          echo "  - mixtral-8x7b: 26GB âš ï¸"
          echo ""
          echo "Large models (>30GB):"
          echo "  - llama3.1-70b: 40GB âŒ (needs split or Pro)"
          echo "  - qwen2.5-72b: 42GB âŒ (needs split or Pro)"
          echo ""
          echo "âš ï¸ GitHub Free tier: 2GB file limit"
          echo "ğŸ’¡ Solutions:"
          echo "  1. Use Git LFS (2GB limit per file)"
          echo "  2. Split large files"
          echo "  3. Upgrade to GitHub Pro"
          echo "  4. Use external storage (OneDrive/GDrive)"
      
      - name: âœ… Validation Complete
        run: |
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘                                                           â•‘"
          echo "â•‘          âœ… ALL VALIDATIONS PASSED! âœ…                   â•‘"
          echo "â•‘                                                           â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          echo "ğŸ¯ Summary:"
          echo "  âœ… Environment ready"
          echo "  âœ… All model URLs valid"
          echo "  âœ… Workflow syntax correct"
          echo "  âœ… Documentation complete"
          echo "  âœ… Download tools working"
          echo ""
          echo "âš ï¸ Note: Large models (>30GB) may need file splitting"
          echo ""
          echo "ğŸš€ You can now run real downloads!"
          echo "   Recommended start: mistral-7b or llama3.1-8b"
